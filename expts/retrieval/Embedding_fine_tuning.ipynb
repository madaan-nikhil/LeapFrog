{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding fine-tuning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse\n",
        "\n",
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkA-3tqWG4el",
        "outputId": "e14fe198-3f70-453c-8132-93444515211b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=jja62Mcf5WzJly1Hn4l3JB7e3Q-H-bWF3lK6WW1E7C0'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=jja62Mcf5WzJly1Hn4l3JB7e3Q-H-bWF3lK6WW1E7C0\")\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libgpm2:amd64.\n",
            "(Reading database ... 155207 files and directories currently installed.)\n",
            "Preparing to unpack .../libgpm2_1.20.7-5_amd64.deb ...\n",
            "Unpacking libgpm2:amd64 (1.20.7-5) ...\n",
            "Selecting previously unselected package w3m.\n",
            "Preparing to unpack .../w3m_0.5.3-36build1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-36build1) ...\n",
            "Setting up libgpm2:amd64 (1.20.7-5) ...\n",
            "Setting up w3m (0.5.3-36build1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "train_path = \"/content/drive/MyDrive/IDL-Project/WebQA_data_first_release/WebQA_train_val.json\"\n",
        "q = json.load(open(train_path,'r'))"
      ],
      "metadata": {
        "id": "Ji5D0oK0IdGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCIUf-qo2sfr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import os\n",
        "# import clip\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "try:\n",
        "  from transformers import BertTokenizer\n",
        "except:\n",
        "  %pip install transformers\n",
        "  from transformers import BertTokenizer\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "MODALS = ['img_posFacts','img_negFacts', 'img_posFacts','img_negFacts']\n",
        "\n",
        "class EmbedTunerDataset(Dataset):\n",
        "  def __init__(self,  img_folder, json_data, imgid_map_path, mode='train'):\n",
        "    \n",
        "    self.imgid = pickle.load(open(imgid_map_path, \"rb\")) \n",
        "    self.data = json_data\n",
        "    self.mode = mode\n",
        "    self.img_folder = img_folder\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    self.instances = list(self.data.keys())\n",
        "    self.Qs = [self.data[instance]['Q'].replace('\"', \"\") for instance in self.instances]\n",
        "    # self.lens = [(Q['input_ids'] == 0).nonzero(as_tuple=False)[0][1].numpy() for Q in self.Qs]\n",
        "\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.instances)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    source_feats = defaultdict(list)\n",
        "    sources = self.data[self.instances[idx]] # all sources of this idx\n",
        "    pos_neg_tag = None\n",
        "    for mode in MODALS:\n",
        "      if len(sources[mode]): # if this type of source exists\n",
        "        for source in sources[mode]:\n",
        "          \n",
        "          if 'img' in mode: # if it is img load feats\n",
        "            image_id = self.imgid[int(source['image_id'])]\n",
        "            feats = os.path.join(self.img_folder, \\\n",
        "                                 \"{}/{}/{}.pkl\".format(self.mode,\\\n",
        "                                                       (image_id%10000000)//1000,\\\n",
        "                                                       image_id))\n",
        "            \n",
        "            with open(feats,'rb') as f:\n",
        "              feats = pickle.load(f)\n",
        "              img = feats['fc1_features'].detach().cpu().float()\n",
        "              cls_label = feats['cls_features'].detach().cpu().float()\n",
        "              feats = torch.cat([img, cls_label], dim=1).mean(dim=0)\n",
        "            \n",
        "          else: # it is a txt source\n",
        "            feats = source['fact'].replace('\"', \"\")\n",
        "\n",
        "          pos_neg_tag = 1. if 'pos' in mode else -1\n",
        "          source_feats[mode].append((feats,pos_neg_tag))\n",
        "\n",
        "    return self.Qs[idx], source_feats\n",
        "  \n",
        "  @staticmethod\n",
        "  def collate_fn(batch):\n",
        "    Qs = [b[0] for b in batch]\n",
        "    source_feats = [b[1] for b in batch] # these are dicts with each type of source\n",
        "\n",
        "    new_batches = []\n",
        "    qs, srcs, src_types, tags = [], [], [], []\n",
        "    for q, source_feat in zip(Qs, source_feats):\n",
        "      for key, val in source_feat.items():\n",
        "        src_type = 'img' if 'img' in key else 'txt'\n",
        "        for src, tag in val:\n",
        "          # datapt = (q, src, src_type, tag) # q_tokens, img or txt feats, type\n",
        "          # new_batches.append(datapt)\n",
        "          qs.append(q), srcs.append(src), src_types.append(src_type), tags.append(tag)\n",
        "\n",
        "    return (qs, srcs, src_types, tags)\n",
        "\n",
        "\n",
        "\n",
        "# test_path = \"/content/drive/MyDrive/18-786-Intro-DL/IDL-Project/WebQA_data_first_release/WebQA_test.json\"\n",
        "# q =  json.load(open(test_path,'r'))\n",
        "\n",
        "img_folder = \"/content/drive/MyDrive/IDL-Project/WebQA 101 Features\"# path to feats folder\n",
        "imgid_map_path = \"/content/drive/MyDrive/IDL-Project/WebQA 101 Features/image_id_map_0328.pkl\"#path to map file\n",
        "\n",
        "val_pts = {k:v for k,v in q.items() if v['split'] == 'val'}\n",
        "train_pts = {k:v for k,v in q.items() if v['split'] == 'train'}\n",
        "\n",
        "train_loader = DataLoader(EmbedTunerDataset(img_folder, train_pts, imgid_map_path, mode='train'),batch_size=5,shuffle=True, collate_fn=EmbedTunerDataset.collate_fn)\n",
        "val_loader = DataLoader(EmbedTunerDataset(img_folder, val_pts, imgid_map_path, mode='val'),batch_size=5,shuffle=False, collate_fn=EmbedTunerDataset.collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[1][0]"
      ],
      "metadata": {
        "id": "BNyXczGPL1eU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7540b50f-b89f-4683-d22b-77546210fe94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.3101, -2.8742, -2.4465,  ...,  1.3623, -0.7533, 13.8441])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J9dyke4GEY4",
        "outputId": "5501cd3f-6a82-420e-ed33-ec3d8bd27da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-252_z3rp\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-252_z3rp\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.12.0+cu113)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2021.10.8)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369389 sha256=5a27ddb57dcdc444058e320526336ab3a59f9f0bccf00a9ac5a5612e5b5ee234\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w6cw13xk/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import clip\n",
        "import numpy as np\n",
        "\n",
        "class Clip_Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Clip_Model, self).__init__()\n",
        "        \n",
        "        # print(configuration.hidden_size)\n",
        "        self.model, self.preprocess = clip.load(\"ViT-B/32\") \n",
        "        self.linear_img = nn.Linear(3649, 512)\n",
        "        self.linear_txt = nn.Linear(512, 512)\n",
        "\n",
        "    def forward(self, qs, feats, ftype):\n",
        "        question_tokens   = clip.tokenize(qs, truncate=True).to(\"cuda\")\n",
        "        question_features = self.model.encode_text(question_tokens).float()\n",
        "        ftype = np.array(ftype)\n",
        "        img_idx = np.where(ftype=='img')[0]\n",
        "        txt_idx = np.where(ftype=='txt')[0]\n",
        "        feats_img = [feats[i] for i in img_idx]\n",
        "        feats_txt = [feats[i] for i in txt_idx]\n",
        "        features = []\n",
        "        question_features_ordered = []\n",
        "        # print(f'feats_img {feats_img}')\n",
        "        # print(f'feats_img {torch.stack(feats_img, dim=0).shape}')\n",
        "        if len(txt_idx):\n",
        "          knowledge_source_tokens = clip.tokenize(feats_txt, truncate=True).to(\"cuda\")\n",
        "          knowledge_source_feats = self.model.encode_text(knowledge_source_tokens).float()\n",
        "          features.extend(self.linear_txt(knowledge_source_feats))\n",
        "          question_features_ordered.extend(question_features[txt_idx])\n",
        "        if len(img_idx):\n",
        "          features.extend(self.linear_img(torch.stack(feats_img, dim=0)))\n",
        "          question_features_ordered.extend(question_features[img_idx])\n",
        "        \n",
        "        # print(f'question_features_ordered {torch.cat(question_features_ordered, dim=0).shape}')\n",
        "        # print(f'features {torch.cat(features, dim=0).shape}')\n",
        "        return torch.stack(question_features_ordered, dim=0), torch.stack(features, dim=0)\n",
        "        "
      ],
      "metadata": {
        "id": "6WQVR1IsF_dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def customLoss(q_feat, src_feat, tag):\n",
        "  # loss = tag*(torch.norm(q_feat-src_feat, dim=1)) + (1-tag)*(-torch.norm(q_feat-src_feat, dim=1))\n",
        "  loss = torch.nn.CosineEmbeddingLoss(reduction=\"sum\")(q_feat, src_feat, tag)\n",
        "  return loss\n",
        "\n",
        "def train(model, train_dataloader, epochs, optimizer):\n",
        "  model.train()\n",
        "\n",
        "  total_acc_train = 0\n",
        "  total_loss_train = 0\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    num_egs = 0.0\n",
        "    model.train()\n",
        "    model.model.requires_grad_(False)\n",
        "\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, position=0, leave=False, desc='Train')\n",
        "\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "      # print(len(data))\n",
        "      (qs, feats, featType, tag) = data\n",
        "      num_egs += len(qs)\n",
        "      \n",
        "      # print(input_id)\n",
        "\n",
        "      question_features, features = model(qs, feats, featType)\n",
        "      \n",
        "      batch_loss = customLoss(question_features.to(device), features.to(device), torch.tensor(tag).to(device))\n",
        "      total_loss_train += batch_loss.item()\n",
        "      \n",
        "\n",
        "      model.zero_grad()\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      batch_bar.set_postfix(loss=\"{:.06f}\".format(total_loss_train/num_egs))\n",
        "\n",
        "      batch_bar.update()\n",
        "    \n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    print(f'Train loss is total_acc_val {total_loss_train/num_egs}')\n",
        "\n",
        "    # total_loss_val = 0.0\n",
        "    # total_acc_val = 0.0\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #   num_egs = 0.0\n",
        "    #   model.eval()\n",
        "    #   batch_bar = tqdm(total=len(val_dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "\n",
        "    #   for batch_idx, (qs, length, modality) in enumerate(val_dataloader):\n",
        "    #       num_egs += modality.shape[0]\n",
        "    #       modality = modality.to(device)\n",
        "    #       mask = qs['attention_mask'].to(device)\n",
        "    #       input_id = qs['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "    #       output = model(input_id, mask)\n",
        "\n",
        "    #       batch_loss = criterion(output, modality)\n",
        "    #       total_loss_val += batch_loss.item()\n",
        "          \n",
        "    #       acc = (output.argmax(dim=1) == modality).sum().item()\n",
        "    #       total_acc_val += acc\n",
        "\n",
        "    #       batch_bar.set_postfix(acc=\"{:.06f}\".format(total_acc_val/num_egs))\n",
        "\n",
        "    #       batch_bar.update()\n",
        "\n",
        "    #   batch_bar.close()\n",
        "\n",
        "    #   save(model, args, epoch, optimizer, None)\n",
        "    \n",
        "    #   print(f'Val accuracy is total_acc_val {total_acc_val/num_egs}')\n"
      ],
      "metadata": {
        "id": "hJMd6SqoU5KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Clip_Model()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "epochs = 10\n",
        "train(model, train_loader, epochs, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "s1aXY-b2eS9l",
        "outputId": "d9ee9797-3025-43d6-c870-0986eadc176d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  23%|██▎       | 1655/7354 [16:56<1:00:11,  1.58it/s, loss=0.054214]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-9dea75a63128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-456cfc21f769>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, epochs, optimizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbatch_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_ncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0;31m# print(len(data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-4527137a5f6c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/140/40140580.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m               \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m               \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc1_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m               \u001b[0mcls_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "\n",
        "model, preprocess = clip.load(\"ViT-B/32\")\n",
        "question_tokens   = clip.tokenize([\"question\"]).to(\"cuda\")\n",
        "question_features = model.encode_text(question_tokens).float()"
      ],
      "metadata": {
        "id": "wK397tO0IDEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uUqHe0ATVJL",
        "outputId": "d3e94cfa-b836-4a70-ac87-d8c06a42acf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvJeQjGdIH9T",
        "outputId": "01bdeb2b-4d96-44a4-cf9a-9d7dca0533e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Were Larry Glick and Laurence Gluck born in the same year?',\n",
              " tensor([ 1.3101, -2.8742, -2.4465,  ...,  1.3623, -0.7533, 13.8441]),\n",
              " 'img',\n",
              " 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls \"/content/drive/MyDrive/IDL-Project/WebQA 101 Features/Train/\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZzBKJoIKrJ",
        "outputId": "a1bef401-932f-4d38-daee-c6a0d07e07a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!7za x /content/drive/MyDrive/IDL-Project/Web_QA_feats_subset"
      ],
      "metadata": {
        "id": "TF-LPgkuKv3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab3b140-9ae0-4efd-ebb2-9264a9762599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/IDL-Project/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0M 1 Scan /content/drive/MyDrive/IDL-Project/Web_QA_feats_subset/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 folder, 1 file, 564540634 bytes (539 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/IDL-Project/Web_QA_feats_subset/140.7z\n",
            "--\n",
            "Path = /content/drive/MyDrive/IDL-Project/Web_QA_feats_subset/140.7z\n",
            "Type = 7z\n",
            "Physical Size = 564540634\n",
            "Headers Size = 4194\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 1\b\b\b\b\b\b      \b\b\b\b\b\b  1% 3 - 140/40140582.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 6 - 140/40140585.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 9 - 140/40140588.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 12 - 140/40140591.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 12 - 140/40140591.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 15 - 140/40140594.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 18 - 140/40140597.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 21 - 140/40140600.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 23 - 140/40140602.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 23 - 140/40140602.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 26 - 140/40140605.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 29 - 140/40140608.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 32 - 140/40140611.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 35 - 140/40140614.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 38 - 140/40140617.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 38 - 140/40140617.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 41 - 140/40140620.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 43 - 140/40140622.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 46 - 140/40140625.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 49 - 140/40140628.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 49 - 140/40140628.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 52 - 140/40140631.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 55 - 140/40140634.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 58 - 140/40140637.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 61 - 140/40140640.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 64 - 140/40140643.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 65 - 140/40140644.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 66 - 140/40140645.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 69 - 140/40140648.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 72 - 140/40140651.pkl\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 75 - 140/40140654.pkl"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok6VXwUXMhFq",
        "outputId": "2f23807a-d1e5-449f-a831-df90fc90a99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/140/40140580.pkl','rb') as f:\n",
        "  x = pickle.load(f)"
      ],
      "metadata": {
        "id": "h-ukkVMCMtM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x['fc1_features'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTejqrr9OJQS",
        "outputId": "cfbc6f8e-3f69-48d2-e110-f5f58467093f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 2048])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x['cls_features'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w28OZBvP3Oz",
        "outputId": "08708278-265a-41f7-a208-a989f341714c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1601])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x['pred_boxes'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIdruYl7P6H8",
        "outputId": "5ba2df7d-5801-4ea8-b3a3-588f4a02ea6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "features = x\n",
        "\n",
        "img = features['fc1_features'].detach().cpu().float()\n",
        "cls_label = features['cls_features'].detach().cpu().float()\n",
        "feats = torch.cat([img, cls_label], dim=1).mean(dim=0)\n",
        "# vis_pe = features['pred_boxes'].detach().cpu()\n",
        "\n",
        "# Lazy normalization of the coordinates\n",
        "# w_est = torch.max(vis_pe[:, [0, 2]])*1.+1e-5\n",
        "# h_est = torch.max(vis_pe[:, [1, 3]])*1.+1e-5\n",
        "# vis_pe[:, [0, 2]] /= w_est\n",
        "# vis_pe[:, [1, 3]] /= h_est\n",
        "\n",
        "# rel_area = (vis_pe[:, 3]-vis_pe[:, 1])*(vis_pe[:, 2]-vis_pe[:, 0])\n",
        "# rel_area.clamp_(0)\n",
        "\n",
        "# vis_pe = torch.cat((vis_pe[:, :4], rel_area.view(-1, 1), features['scores'].detach().cpu().view(-1, 1)), -1)\n",
        "# normalized_coord = F.normalize(vis_pe.data[:, :5] - 0.5, dim=-1)\n",
        "# vis_pe = torch.cat((F.layer_norm(vis_pe, [6]), F.layer_norm(cls_label, [1601])), dim=-1)\n",
        "\n",
        "# assert img.size(0) == vis_pe.size(0), \"img features and vis_pe should have the same token length!\"\n",
        "# vis_pad = torch.zeros((self.max_len_img_cxt - img.size(0), img.size(-1)))\n",
        "# img = torch.cat((img, vis_pad), dim=0) \n",
        "# pe_pad = torch.zeros((self.max_len_img_cxt - vis_pe.size(0), vis_pe.size(-1)))\n",
        "# vis_pe = torch.cat((vis_pe, pe_pad), dim=0)\n",
        "# assert vis_pe.size(0) == self.max_len_img_cxt\n",
        "# assert img.size(0) == self.max_len_img_cxt\n",
        "# input_ids_list.append(torch.tensor(input_ids))\n",
        "# segment_ids_list.append(torch.tensor(segment_ids))\n",
        "# input_mask_list.append(input_mask)\n",
        "# if not self.use_img_content: \n",
        "#     img = torch.zeros_like(img).float()\n",
        "#     vis_pe = torch.zeros_like(vis_pe).float()\n",
        "# img_list.append(img)\n",
        "# vis_pe_list.append(vis_pe)"
      ],
      "metadata": {
        "id": "zWlSuiUXOQUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAXdO2VOQTQz",
        "outputId": "b1097e64-f767-420e-8036-5c551678c2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3649])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def customLoss(q_feat, src_feat, tag, eps):\n",
        "  loss = tag*(torch.norm(q_feat-src_feat, dim=1)) + (1-tag)*torch.max(0,eps-torch.norm(q_feat-src_feat, dim=1))\n",
        "  return torch.mean(loss)"
      ],
      "metadata": {
        "id": "EentPnTqQUpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1,2,3,4,5]\n",
        "\n",
        "x[2,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7C8AQ30kI1bT",
        "outputId": "3e3ecebf-7300-4b95-8297-310d8df78ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3a1e8cb69fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['img', 'img', 'img']"
      ],
      "metadata": {
        "id": "tVYYGW13I3p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(x=='img')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKUWINSeJ_CY",
        "outputId": "a51bdb79-f7f2-4655-caa1-7f1fd42b3450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJKWZPunKC-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}